{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8570fe2c41ea>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:261: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:263: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:268: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:111: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:291: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集train数量： 55000 ,验证集validation数量： 5000 ，测试集test数量： 10000\n",
      "train images shape： (55000, 784) labels shape: (55000, 10)\n",
      "validation images shape： (5000, 784) labels shape: (5000, 10)\n",
      "test images shape： (10000, 784) labels shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('训练集train数量：', mnist.train.num_examples, ',验证集validation数量：', mnist.validation.num_examples, '，测试集test数量：', mnist.test.num_examples)\n",
    "print('train images shape：', mnist.train.images.shape, 'labels shape:', mnist.train.labels.shape)\n",
    "print('validation images shape：', mnist.validation.images.shape, 'labels shape:', mnist.validation.labels.shape)\n",
    "print('test images shape：', mnist.test.images.shape, 'labels shape:', mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.images[0])  # images图像28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3803922 , 0.37647063, 0.3019608 ,\n",
       "       0.46274513, 0.2392157 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3529412 , 0.5411765 , 0.9215687 ,\n",
       "       0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
       "       0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,\n",
       "       0.9215687 , 0.74509805, 0.08235294, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "       0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.7411765 , 0.09019608, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
       "       0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
       "       0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
       "       0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
       "       0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.32156864, 0.0509804 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
       "       0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.32941177, 0.9960785 ,\n",
       "       0.9960785 , 0.9176471 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4156863 , 0.6156863 ,\n",
       "       0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
       "       0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.26666668, 0.4666667 , 0.86274517,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.14509805, 0.73333335,\n",
       "       0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,\n",
       "       0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,\n",
       "       0.9960785 , 0.9960785 , 0.45882356, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,\n",
       "       0.45098042, 0.34901962, 0.12156864, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7843138 , 0.9960785 , 0.9450981 ,\n",
       "       0.16078432, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "       0.6901961 , 0.24313727, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823531,\n",
       "       0.9058824 , 0.9960785 , 0.9176471 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "       0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8235295 , 0.9803922 , 0.9960785 ,\n",
       "       0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34901962, 0.9843138 , 0.9450981 ,\n",
       "       0.3372549 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "       0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01568628, 0.45882356, 0.27058825,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3803922 , 0.37647063, 0.3019608 , 0.46274513,\n",
       "        0.2392157 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.3529412 , 0.5411765 ,\n",
       "        0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
       "        0.9215687 , 0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 ,\n",
       "        0.9607844 , 0.9215687 , 0.74509805, 0.08235294, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.54901963, 0.9843138 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.7411765 , 0.09019608,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
       "        0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
       "        0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
       "        0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
       "        0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.14901961, 0.32156864, 0.0509804 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13333334, 0.8352942 , 0.9960785 , 0.9960785 ,\n",
       "        0.45098042, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "        0.9176471 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "        0.9176471 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4156863 , 0.6156863 , 0.9960785 , 0.9960785 ,\n",
       "        0.95294124, 0.20000002, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
       "        0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26666668,\n",
       "        0.4666667 , 0.86274517, 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.5568628 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14509805, 0.73333335, 0.9921569 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 , 0.8078432 ,\n",
       "        0.8078432 , 0.29411766, 0.26666668, 0.8431373 , 0.9960785 ,\n",
       "        0.9960785 , 0.45882356, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 ,\n",
       "        0.89019614, 0.45098042, 0.34901962, 0.12156864, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.7843138 , 0.9960785 ,\n",
       "        0.9450981 , 0.16078432, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.6627451 , 0.9960785 , 0.6901961 , 0.24313727,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.18823531, 0.9058824 , 0.9960785 ,\n",
       "        0.9176471 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "        0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.54509807, 0.9960785 , 0.9333334 ,\n",
       "        0.22352943, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.8235295 , 0.9803922 , 0.9960785 , 0.65882355,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.9490197 , 0.9960785 , 0.93725497, 0.22352943,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34901962, 0.9843138 , 0.9450981 , 0.3372549 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "        0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
       "        0.45882356, 0.27058825, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[0].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADkFJREFUeJzt3W+IXPW9x/HP99r2gbYP1I1LsLFbQcwGoWkc4oWamNLb\nYqQQu4KoUHNBuj7ojQby4OqaUBHFUNoEH5Tq5jY0arS9kL8PXEVDdVO4lIyS65+suXpl1ybE7CwW\nanzSar99sMey1T2/M86ZmTO73/cLlp053zl7vhz95MzM75zzM3cXgHj+peoGAFSD8ANBEX4gKMIP\nBEX4gaAIPxAU4QeCIvxAUIQfCOoL3dxYX1+fDwwMdHOTQCiTk5OamZmxZl5bKvxmdr2kRySdJ+m/\n3H176vUDAwOq1+tlNgkgoVarNf3alt/2m9l5kn4hab2kFZJuNbMVrf49AN1V5jP/aklvu/s77v4X\nSb+RtKE9bQHotDLhv1TSH+c8P5Ut+ydmNmxmdTOrNxqNEpsD0E4d/7bf3UfdvebutSVLlnR6cwCa\nVCb8pyUtm/P8q9kyAAtAmfAfk3SFmX3dzL4k6RZJh9vTFoBOa3moz90/MrP/kPScZof6drv7G23r\nDEBHlRrnd/dnJD3Tpl4AdBGn9wJBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E\nRfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIP\nBEX4gaAIPxBUqVl6zWxS0geSPpb0kbvX2tEUumdqaipZ37VrV7L+0EMPJetmlltz9+S6g4ODyfqD\nDz6YrA8NDSXr0ZUKf+bb7j7Thr8DoIt42w8EVTb8LukFM3vZzIbb0RCA7ij7tv9adz9tZpdIet7M\n3nT38bkvyP5RGJakyy67rOTmALRLqSO/u5/Ofk9LOiBp9TyvGXX3mrvXlixZUmZzANqo5fCb2QVm\n9pVPHkv6nqTX29UYgM4q87a/X9KBbCjnC5Kecvdn29IVgI5rOfzu/o6kb7SxF7So0Wjk1h5++OHk\nunv37k3WZ2bSo7ipcfxm6iknT55M1rds2ZKsr127NrfW19fXUk+LCUN9QFCEHwiK8ANBEX4gKMIP\nBEX4gaDacVUfOqzo0tVt27bl1oqG2oouqy1av+iU7TJndRYNM05OTibrqaG+EydOtNLSosKRHwiK\n8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpx/ATh06FCynhqLL3NJrSStWLEiWX/xxReT9TKXzh49ejRZ\nv+6665L1okuCo+PIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc7fAyYmJpL1N998M1lPXVNfdD19\n0Tj8jh07kvWtW7cm6yMjI7m1onsBrFmzJlkvuhdByujoaLI+PLz4p57kyA8ERfiBoAg/EBThB4Ii\n/EBQhB8IivADQRWO85vZbknflzTt7ldlyy6S9FtJA5ImJd3s7n/qXJuL2+DgYLJ+7NixZD01Vl92\nKuqi8fAy4+VF4/z79+9P1stMDz40NJRcN4Jmjvy/lnT9p5bdI+mIu18h6Uj2HMACUhh+dx+X9P6n\nFm+QtCd7vEfSjW3uC0CHtfqZv9/dz2SP35PU36Z+AHRJ6S/8fPYE69yTrM1s2MzqZlZvNBplNweg\nTVoN/1kzWypJ2e/pvBe6+6i719y9VmbSRgDt1Wr4D0vamD3eKCl9e1kAPacw/Gb2tKT/kXSlmZ0y\nszskbZf0XTN7S9K/Zc8BLCCF4/zufmtO6Ttt7gU5li9fXtm2i84TuPLKK5P1iy++OLe2c+fO5Lrb\nt6ePKUXX86c+ZpY9/2Ex4Aw/ICjCDwRF+IGgCD8QFOEHgiL8QFDcunsRGB8fz60V3fa7aMir6HLj\nommwr7nmmtza9HTuiaGSii/ZveSSS5L1sbGxZD06jvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj\n/IvAU089lVsrurV20WWxRWPtReunxvLLXJIrSZs2bUrWV61alaxHx5EfCIrwA0ERfiAowg8ERfiB\noAg/EBThB4JinH+RKxqnr3L9tWvXJtfdsWNHss44fjkc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4g\nqMJxfjPbLen7kqbd/aps2f2SfiSpkb1sxN2f6VSTSLvttttya1NTU8l1Z2ZmkvWi+/6fO3cuWU95\n4IEHknXG8TurmSP/ryVdP8/yne6+Mvsh+MACUxh+dx+X9H4XegHQRWU+828ys1fNbLeZXdi2jgB0\nRavh/6WkyyWtlHRG0s/zXmhmw2ZWN7N6o9HIexmALmsp/O5+1t0/dve/SdolaXXitaPuXnP3WtEN\nGQF0T0vhN7Olc57+QNLr7WkHQLc0M9T3tKR1kvrM7JSkn0haZ2YrJbmkSUl3drBHAB1gRfdOb6da\nreb1er1r20N5ReP89913X7J+8ODB3FrROP7Y2Fiy3tfXl6xHVKvVVK/Xm7oJA2f4AUERfiAowg8E\nRfiBoAg/EBThB4Li1t1NSp2avJjPXFy+fHmyvm/fvmR9/fr1ubVnn302ue6TTz6ZrG/evDlZRxpH\nfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+zPj4eLK+ZcuW3FrRWPgTTzzRUk+LwcjISG7tueee\nS6578uTJdreDOTjyA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQYcb5i6YKu/PO9NQD/f39ubXI4/gf\nfvhhsp7ar928bTw+iyM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRVOM5vZsskPS6pX5JLGnX3R8zs\nIkm/lTQgaVLSze7+p861Ws6BAweS9aJrx9etW9fGbhaOiYmJZP2mm25K1lP71Sw9k3TRfRJQTjNH\n/o8kbXH3FZL+VdKPzWyFpHskHXH3KyQdyZ4DWCAKw+/uZ9z9lezxB5ImJF0qaYOkPdnL9ki6sVNN\nAmi/z/WZ38wGJH1T0h8k9bv7maz0nmY/FgBYIJoOv5l9WdI+SZvd/c9zaz57kva8J2qb2bCZ1c2s\nXnR+PYDuaSr8ZvZFzQZ/r7vvzxafNbOlWX2ppOn51nX3UXevuXttMU9oCSw0heG32a9kfyVpwt13\nzCkdlrQxe7xR0qH2twegU5q5pPdbkn4o6TUzO54tG5G0XdJ/m9kdkqYk3dyZFttjzZo1yXrR5aUv\nvfRSbq1oKunBwcFk/eqrr07Wi0xNTeXWjh49mlx3//79yfrBgweT9aL9lhrOK5pi++67707WUU5h\n+N3995Ly/gt+p73tAOgWzvADgiL8QFCEHwiK8ANBEX4gKMIPBBXm1t1FY+1DQ0PJemq8+/bbb0+u\nW3Tp6qpVq5L1Iu+++25ubWZmJrlumXH6ZmzdujW3dtddd5X62yiHIz8QFOEHgiL8QFCEHwiK8ANB\nEX4gKMIPBBVmnL/Io48+mqynxtLr9XqpbRetXzTWnhqrL1r3/PPPT9aLzo+49957k/Wi8ydQHY78\nQFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/yZotmExsbGcmvbtm0rte3HHnssWS+aBruvr6/lbRfd\nG59pshcvjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EJQ1cd/2ZZIel9QvySWNuvsjZna/pB9JamQv\nHXH3Z1J/q1aredlr3wHkq9VqqtfrTU220MxJPh9J2uLur5jZVyS9bGbPZ7Wd7v6zVhsFUJ3C8Lv7\nGUlnsscfmNmEpEs73RiAzvpcn/nNbEDSNyX9IVu0ycxeNbPdZnZhzjrDZlY3s3qj0ZjvJQAq0HT4\nzezLkvZJ2uzuf5b0S0mXS1qp2XcGP59vPXcfdfeau9eKzp8H0D1Nhd/MvqjZ4O919/2S5O5n3f1j\nd/+bpF2SVneuTQDtVhh+m739668kTbj7jjnLl8552Q8kvd7+9gB0SjPf9n9L0g8lvWZmx7NlI5Ju\nNbOVmh3+m5R0Z0c6BNARzXzb/3tJ840bJsf0AfQ2zvADgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAI\nPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXjr7rZuzKwhaWrOoj5JM11r4PPp1d56tS+J3lrVzt6+\n5u5N3S+vq+H/zMbN6u5eq6yBhF7trVf7kuitVVX1xtt+ICjCDwRVdfhHK95+Sq/21qt9SfTWqkp6\nq/QzP4DqVH3kB1CRSsJvZteb2Ukze9vM7qmihzxmNmlmr5nZcTOrdErhbBq0aTN7fc6yi8zseTN7\nK/s97zRpFfV2v5mdzvbdcTO7oaLelpnZ78zshJm9YWZ3Z8sr3XeJvirZb11/229m50n6P0nflXRK\n0jFJt7r7ia42ksPMJiXV3L3yMWEzWyvpnKTH3f2qbNlPJb3v7tuzfzgvdPf/7JHe7pd0ruqZm7MJ\nZZbOnVla0o2S/l0V7rtEXzergv1WxZF/taS33f0dd/+LpN9I2lBBHz3P3cclvf+pxRsk7cke79Hs\n/zxdl9NbT3D3M+7+Svb4A0mfzCxd6b5L9FWJKsJ/qaQ/znl+Sr015bdLesHMXjaz4aqbmUd/Nm26\nJL0nqb/KZuZROHNzN31qZume2XetzHjdbnzh91nXuvtKSesl/Th7e9uTfPYzWy8N1zQ1c3O3zDOz\n9D9Uue9anfG63aoI/2lJy+Y8/2q2rCe4++ns97SkA+q92YfPfjJJavZ7uuJ+/qGXZm6eb2Zp9cC+\n66UZr6sI/zFJV5jZ183sS5JukXS4gj4+w8wuyL6IkZldIOl76r3Zhw9L2pg93ijpUIW9/JNembk5\nb2ZpVbzvem7Ga3fv+o+kGzT7jf//S7qvih5y+rpc0v9mP29U3ZukpzX7NvCvmv1u5A5JF0s6Iukt\nSS9IuqiHentC0muSXtVs0JZW1Nu1mn1L/6qk49nPDVXvu0Rflew3zvADguILPyAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQf0dRtCBZeeE+r4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1111bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_image(image):\n",
    "    plt.imshow(image.reshape(28,28), cmap='binary')\n",
    "    plt.show()\n",
    "plot_image(mnist.train.images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
       "       [16, 17, 18, 19, 20, 21, 22, 23],\n",
       "       [24, 25, 26, 27, 28, 29, 30, 31],\n",
       "       [32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47],\n",
       "       [48, 49, 50, 51, 52, 53, 54, 55],\n",
       "       [56, 57, 58, 59, 60, 61, 62, 63]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "int_array=np.array([i for i in range(64)])\n",
    "print(int_array)\n",
    "int_array.reshape(8,8)  # reshape行优先，逐行排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[1]   # 独热编码形式\n",
    "# 从独热编码数组中读取出所表示的数字值\n",
    "np.argmax(mnist.train.labels[1])  # argmax返回的是最大数的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "[7 3 4 6 1 8 1 0 9 8]\n"
     ]
    }
   ],
   "source": [
    "mnist_no_one_hot = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "# 非独热编码的标签值\n",
    "print(mnist_no_one_hot.train.labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images[0:10])\n",
    "print(mnist.train.labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784) (10, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 数据的批量读取 next_batch()实现内部会对数据集先做shuffle\n",
    "batch_images_xs, batch_labels_ys = mnist.train.next_batch(batch_size=10)  # image和标签数据\n",
    "print(batch_images_xs.shape, batch_labels_ys.shape)\n",
    "print(batch_labels_ys)  #每重新运行一次往后读取10个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mnist中每张图片共有28*28=784个像素点\n",
    "x = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "# 0-9一共10个数字即10个类别\n",
    "y = tf.placeholder(tf.float32, [None, 10], name=\"Y\")\n",
    "# 定义变量\n",
    "W = tf.Variable(tf.random_normal([784, 10]), name=\"W\")\n",
    "b = tf.Variable(tf.zeros([10]), name=\"b\")\n",
    "# 用单个神经元构建神经网络\n",
    "forward = tf.matmul(x, W)+b  #前向计算\n",
    "pred = tf.nn.softmax(forward)  #Softmax分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置训练参数\n",
    "train_epochs = 50  # 训练轮数\n",
    "batch_size = 50   # 单次训练样本数（批次大小）\n",
    "total_batch = int(mnist.train.num_examples/batch_size)  # 一轮训练有多少批次\n",
    "display_step = 1  # 显示粒度\n",
    "learning_rate = 0.05  # 学习率\n",
    "# 定义交叉熵损失函数\n",
    "loss_function = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "# 梯度下降优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 检查预测类别tf.argmax(pred,1)与实际类别tf.argmax(y,1)的匹配情况\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y,1))\n",
    "# 准确率，将布尔值转化为浮点数，并计算平均值\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 01 Loss= 1.261252880 Accuracy= 0.7440\n",
      "Train Epoch: 02 Loss= 0.903792202 Accuracy= 0.8096\n",
      "Train Epoch: 03 Loss= 0.753053248 Accuracy= 0.8348\n",
      "Train Epoch: 04 Loss= 0.676663458 Accuracy= 0.8524\n",
      "Train Epoch: 05 Loss= 0.621370137 Accuracy= 0.8636\n",
      "Train Epoch: 06 Loss= 0.587194800 Accuracy= 0.8728\n",
      "Train Epoch: 07 Loss= 0.555028617 Accuracy= 0.8786\n",
      "Train Epoch: 08 Loss= 0.534038067 Accuracy= 0.8802\n",
      "Train Epoch: 09 Loss= 0.517303705 Accuracy= 0.8848\n",
      "Train Epoch: 10 Loss= 0.497368455 Accuracy= 0.8870\n",
      "Train Epoch: 11 Loss= 0.489362299 Accuracy= 0.8892\n",
      "Train Epoch: 12 Loss= 0.473220766 Accuracy= 0.8908\n",
      "Train Epoch: 13 Loss= 0.461093366 Accuracy= 0.8928\n",
      "Train Epoch: 14 Loss= 0.453457177 Accuracy= 0.8944\n",
      "Train Epoch: 15 Loss= 0.447694093 Accuracy= 0.8958\n",
      "Train Epoch: 16 Loss= 0.437987119 Accuracy= 0.8970\n",
      "Train Epoch: 17 Loss= 0.430691153 Accuracy= 0.8984\n",
      "Train Epoch: 18 Loss= 0.423843563 Accuracy= 0.9000\n",
      "Train Epoch: 19 Loss= 0.421007484 Accuracy= 0.9016\n",
      "Train Epoch: 20 Loss= 0.413238227 Accuracy= 0.9026\n",
      "Train Epoch: 21 Loss= 0.410461128 Accuracy= 0.9034\n",
      "Train Epoch: 22 Loss= 0.404096395 Accuracy= 0.9026\n",
      "Train Epoch: 23 Loss= 0.400703877 Accuracy= 0.9028\n",
      "Train Epoch: 24 Loss= 0.395205975 Accuracy= 0.9038\n",
      "Train Epoch: 25 Loss= 0.392787814 Accuracy= 0.9062\n",
      "Train Epoch: 26 Loss= 0.385854006 Accuracy= 0.9062\n",
      "Train Epoch: 27 Loss= 0.382910728 Accuracy= 0.9068\n",
      "Train Epoch: 28 Loss= 0.381644577 Accuracy= 0.9076\n",
      "Train Epoch: 29 Loss= 0.378434867 Accuracy= 0.9090\n",
      "Train Epoch: 30 Loss= 0.375264168 Accuracy= 0.9076\n",
      "Train Epoch: 31 Loss= 0.373538405 Accuracy= 0.9064\n",
      "Train Epoch: 32 Loss= 0.368052483 Accuracy= 0.9104\n",
      "Train Epoch: 33 Loss= 0.367756307 Accuracy= 0.9092\n",
      "Train Epoch: 34 Loss= 0.363816559 Accuracy= 0.9098\n",
      "Train Epoch: 35 Loss= 0.362464070 Accuracy= 0.9118\n",
      "Train Epoch: 36 Loss= 0.361305326 Accuracy= 0.9116\n",
      "Train Epoch: 37 Loss= 0.358990580 Accuracy= 0.9114\n",
      "Train Epoch: 38 Loss= 0.355460048 Accuracy= 0.9132\n",
      "Train Epoch: 39 Loss= 0.354509145 Accuracy= 0.9110\n",
      "Train Epoch: 40 Loss= 0.353550404 Accuracy= 0.9120\n",
      "Train Epoch: 41 Loss= 0.350809276 Accuracy= 0.9116\n",
      "Train Epoch: 42 Loss= 0.348578721 Accuracy= 0.9126\n",
      "Train Epoch: 43 Loss= 0.348535001 Accuracy= 0.9128\n",
      "Train Epoch: 44 Loss= 0.345497400 Accuracy= 0.9144\n",
      "Train Epoch: 45 Loss= 0.345342100 Accuracy= 0.9124\n",
      "Train Epoch: 46 Loss= 0.344059825 Accuracy= 0.9138\n",
      "Train Epoch: 47 Loss= 0.342528135 Accuracy= 0.9130\n",
      "Train Epoch: 48 Loss= 0.340391248 Accuracy= 0.9154\n",
      "Train Epoch: 49 Loss= 0.339173645 Accuracy= 0.9140\n",
      "Train Epoch: 50 Loss= 0.337507665 Accuracy= 0.9160\n",
      "Train Finished!\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "for epoch in range(train_epochs):\n",
    "    for batch in range(total_batch):\n",
    "        xs, ys = mnist.train.next_batch(batch_size)  # 读取批次数据\n",
    "        sess.run(optimizer, feed_dict={x:xs, y:ys})  # 执行批次训练\n",
    "    \n",
    "    # total_batch个批次训练完成后，使用验证数据计算误差与准确率；验证集没有分批\n",
    "    loss, acc = sess.run([loss_function, accuracy], feed_dict={x:mnist.validation.images, y:mnist.validation.labels})\n",
    "    # 打印训练过程中的详细信息\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Train Epoch:\", \"%02d\" % (epoch+1), \"Loss=\", \"{:.9f}\".format(loss), \"Accuracy=\", \"{:.4f}\".format(acc))\n",
    "print(\"Train Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9083\n"
     ]
    }
   ],
   "source": [
    "# 完成训练后，在测试集上评估模型的准确率\n",
    "accu_test = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "print(\"Test Accuracy:\", accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 6 7]\n"
     ]
    }
   ],
   "source": [
    "# 由于pred预测结果是独热编码格式，所以需要转换为0-9数字\n",
    "prediction_result = sess.run(tf.argmax(pred, 1), feed_dict={x:mnist.test.images})\n",
    "# 查看预测结果中的前10项\n",
    "print(prediction_result[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAEHCAYAAACtGEJ8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3E4HygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12335358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_images_labels_prediction(images, labels, prediction, index, num=10):\n",
    "    fig = plt.gcf()  # 获取当前图表\n",
    "    fig.set_size_inches(10, 12)\n",
    "    if num > 25:\n",
    "        num = 25    # 最多显示25个子图\n",
    "    for i in range(0, num):\n",
    "        ax = plt.subplot(5,5, i+1)\n",
    "        ax.imshow(np.reshape(images[index], (28,28)), cmap=\"binary\")\n",
    "        title=\"label=\" + str(np.argmax(labels[index]))\n",
    "        if len(prediction)>0:\n",
    "            title += \",predict=\" + str(prediction[index])\n",
    "        ax.set_title(title, fontsize=10)\n",
    "        ax.set_xticks([])  # 不显示坐标轴\n",
    "        ax.set_yticks([])\n",
    "        index += 1\n",
    "    plt.show()\n",
    "\n",
    "plot_images_labels_prediction(mnist.test.images, mnist.test.labels, prediction_result, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 全连接单隐藏层网络建模实现\n",
    "x = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, [None, 10], name=\"Y\")\n",
    "# 构建隐藏层\n",
    "H1_NN = 256   # 隐藏层神经元数量\n",
    "W1 = tf.Variable(tf.random_normal([784, H1_NN]))\n",
    "b1 = tf.Variable(tf.zeros([H1_NN]))\n",
    "Y1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "# 构建输出层\n",
    "W2 = tf.Variable(tf.random_normal([H1_NN, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "forward = tf.matmul(Y1, W2) + b2\n",
    "pred = tf.nn.softmax(forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-59-8fb1eed0c135>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置训练参数\n",
    "train_epochs = 40  # 训练轮数\n",
    "batch_size = 50   # 单次训练样本数（批次大小）\n",
    "total_batch = int(mnist.train.num_examples/batch_size)  # 一轮训练有多少批次\n",
    "display_step = 1  # 显示粒度\n",
    "learning_rate = 0.01  # 学习率\n",
    "# 结合Softmax的交叉熵损失函数，用于避免因为log(0)值为NaN造成的数据不稳定\n",
    "loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=forward, labels=y))\n",
    "# Adam优化器\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 01 Loss= 1.262539625 Accuracy= 0.9394\n",
      "Train Epoch: 02 Loss= 0.660062730 Accuracy= 0.9516\n",
      "Train Epoch: 03 Loss= 0.455864489 Accuracy= 0.9556\n",
      "Train Epoch: 04 Loss= 0.353663534 Accuracy= 0.9600\n",
      "Train Epoch: 05 Loss= 0.380880028 Accuracy= 0.9602\n",
      "Train Epoch: 06 Loss= 0.442683786 Accuracy= 0.9514\n",
      "Train Epoch: 07 Loss= 0.343103081 Accuracy= 0.9636\n",
      "Train Epoch: 08 Loss= 0.318359733 Accuracy= 0.9624\n",
      "Train Epoch: 09 Loss= 0.346345246 Accuracy= 0.9630\n",
      "Train Epoch: 10 Loss= 0.395686388 Accuracy= 0.9614\n",
      "Train Epoch: 11 Loss= 0.317907512 Accuracy= 0.9682\n",
      "Train Epoch: 12 Loss= 0.377619445 Accuracy= 0.9662\n",
      "Train Epoch: 13 Loss= 0.351834536 Accuracy= 0.9726\n",
      "Train Epoch: 14 Loss= 0.411350548 Accuracy= 0.9694\n",
      "Train Epoch: 15 Loss= 0.437524796 Accuracy= 0.9646\n",
      "Train Epoch: 16 Loss= 0.416701108 Accuracy= 0.9700\n",
      "Train Epoch: 17 Loss= 0.409879208 Accuracy= 0.9718\n",
      "Train Epoch: 18 Loss= 0.445674717 Accuracy= 0.9704\n",
      "Train Epoch: 19 Loss= 0.478438377 Accuracy= 0.9716\n",
      "Train Epoch: 20 Loss= 0.458832860 Accuracy= 0.9742\n",
      "Train Epoch: 21 Loss= 0.474852085 Accuracy= 0.9686\n",
      "Train Epoch: 22 Loss= 0.484316498 Accuracy= 0.9690\n",
      "Train Epoch: 23 Loss= 0.618757725 Accuracy= 0.9712\n",
      "Train Epoch: 24 Loss= 0.517671168 Accuracy= 0.9732\n",
      "Train Epoch: 25 Loss= 0.570904851 Accuracy= 0.9750\n",
      "Train Epoch: 26 Loss= 0.563663661 Accuracy= 0.9728\n",
      "Train Epoch: 27 Loss= 0.564888477 Accuracy= 0.9732\n",
      "Train Epoch: 28 Loss= 0.565896928 Accuracy= 0.9734\n",
      "Train Epoch: 29 Loss= 0.677886248 Accuracy= 0.9698\n",
      "Train Epoch: 30 Loss= 0.648955584 Accuracy= 0.9732\n",
      "Train Epoch: 31 Loss= 0.563732624 Accuracy= 0.9758\n",
      "Train Epoch: 32 Loss= 0.588717341 Accuracy= 0.9740\n",
      "Train Epoch: 33 Loss= 0.749070227 Accuracy= 0.9762\n",
      "Train Epoch: 34 Loss= 0.681663156 Accuracy= 0.9764\n",
      "Train Epoch: 35 Loss= 0.834365845 Accuracy= 0.9756\n",
      "Train Epoch: 36 Loss= 0.842924714 Accuracy= 0.9732\n",
      "Train Epoch: 37 Loss= 0.860177457 Accuracy= 0.9752\n",
      "Train Epoch: 38 Loss= 0.834421098 Accuracy= 0.9732\n",
      "Train Epoch: 39 Loss= 0.762611508 Accuracy= 0.9734\n",
      "Train Epoch: 40 Loss= 0.773558915 Accuracy= 0.9766\n",
      "Train Finished takes: 107.22\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "startTime = time()\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    for batch in range(total_batch):\n",
    "        xs, ys = mnist.train.next_batch(batch_size)  # 读取批次数据\n",
    "        sess.run(optimizer, feed_dict={x:xs, y:ys})  # 执行批次训练\n",
    "    \n",
    "    # total_batch个批次训练完成后，使用验证数据计算误差与准确率；验证集没有分批\n",
    "    loss, acc = sess.run([loss_function, accuracy], feed_dict={x:mnist.validation.images, y:mnist.validation.labels})\n",
    "    # 打印训练过程中的详细信息\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Train Epoch:\", \"%02d\" % (epoch+1), \"Loss=\", \"{:.9f}\".format(loss), \"Accuracy=\", \"{:.4f}\".format(acc))\n",
    "\n",
    "# 显示运行总时间\n",
    "duration = time()-startTime\n",
    "print(\"Train Finished takes:\", \"{:.2f}\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9738\n"
     ]
    }
   ],
   "source": [
    "# 完成训练后，在测试集上评估模型的准确率\n",
    "accu_test = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "print(\"Test Accuracy:\", accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 6 9]\n"
     ]
    }
   ],
   "source": [
    "# 由于pred预测结果是独热编码格式，所以需要转换为0-9数字\n",
    "prediction_result = sess.run(tf.argmax(pred, 1), feed_dict={x:mnist.test.images})\n",
    "# 查看预测结果中的前10项\n",
    "print(prediction_result[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 104, 121, 151, 217, 241, 247, 292, 321, 340, 406, 445, 447, 495, 582, 591, 619, 629, 655, 659, 674, 684, 720, 726, 844, 877, 882, 924, 938, 947, 951, 956, 965, 1014, 1039, 1050, 1107, 1112, 1226, 1232, 1242, 1247, 1299, 1319, 1328, 1331, 1425, 1466, 1494, 1530, 1549, 1553, 1571, 1601, 1609, 1621, 1678, 1717, 1781, 1878, 1901, 1941, 1955, 1982, 2004, 2016, 2073, 2098, 2105, 2109, 2118, 2130, 2135, 2224, 2272, 2293, 2308, 2358, 2369, 2387, 2408, 2454, 2462, 2488, 2496, 2515, 2578, 2597, 2648, 2654, 2720, 2769, 2770, 2771, 2810, 2863, 2877, 2896, 2915, 2921, 2927, 2938, 2939, 2941, 2953, 2995, 3023, 3030, 3060, 3108, 3284, 3369, 3405, 3475, 3490, 3503, 3520, 3558, 3559, 3597, 3604, 3702, 3776, 3780, 3808, 3831, 3853, 3893, 3906, 3941, 3951, 3976, 3985, 4007, 4065, 4075, 4078, 4116, 4140, 4156, 4163, 4176, 4201, 4212, 4248, 4259, 4271, 4289, 4294, 4373, 4374, 4382, 4429, 4433, 4497, 4498, 4534, 4536, 4548, 4601, 4639, 4721, 4724, 4743, 4761, 4807, 4808, 4823, 4837, 4860, 4861, 4880, 4915, 4944, 4966, 5078, 5331, 5401, 5457, 5642, 5654, 5687, 5734, 5763, 5887, 5888, 5926, 5935, 5936, 5955, 5973, 5982, 6009, 6011, 6023, 6030, 6045, 6059, 6080, 6101, 6157, 6172, 6347, 6555, 6571, 6572, 6574, 6597, 6651, 6755, 6783, 6967, 7061, 7081, 7100, 7256, 7434, 7451, 7481, 7736, 7823, 7849, 7850, 8091, 8246, 8325, 8383, 8408, 8472, 8502, 8520, 8522, 8527, 8863, 9009, 9015, 9019, 9024, 9128, 9252, 9253, 9385, 9530, 9544, 9587, 9664, 9679, 9692, 9713, 9729, 9735, 9740, 9749, 9768, 9770, 9779, 9839, 9858, 9867, 9904, 9925, 9944] 262\n"
     ]
    }
   ],
   "source": [
    "# 找出预测错误\n",
    "compare_lists = prediction_result == np.argmax(mnist.test.labels, 1)\n",
    "err_lists = [i for i in range(len(compare_lists)) if compare_lists[i] == False]\n",
    "print(err_lists, len(err_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAIUCAYAAAAZsijUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1281ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images_labels_prediction(mnist.test.images, mnist.test.labels, prediction_result, 0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=8标签值= 5 预测值= 6\n",
      "index=104标签值= 9 预测值= 5\n",
      "index=121标签值= 4 预测值= 8\n",
      "index=151标签值= 9 预测值= 8\n",
      "index=217标签值= 6 预测值= 5\n",
      "index=241标签值= 9 预测值= 5\n",
      "index=247标签值= 4 预测值= 2\n",
      "index=292标签值= 9 预测值= 7\n",
      "index=321标签值= 2 预测值= 7\n",
      "index=340标签值= 5 预测值= 3\n",
      "index=406标签值= 5 预测值= 6\n",
      "index=445标签值= 6 预测值= 0\n",
      "index=447标签值= 4 预测值= 9\n",
      "index=495标签值= 8 预测值= 0\n",
      "index=582标签值= 8 预测值= 2\n",
      "index=591标签值= 8 预测值= 2\n",
      "index=619标签值= 1 预测值= 8\n",
      "index=629标签值= 2 预测值= 0\n",
      "index=655标签值= 8 预测值= 2\n",
      "index=659标签值= 2 预测值= 8\n",
      "index=674标签值= 5 预测值= 3\n",
      "index=684标签值= 7 预测值= 3\n",
      "index=720标签值= 5 预测值= 8\n",
      "index=726标签值= 7 预测值= 9\n",
      "index=844标签值= 8 预测值= 7\n",
      "index=877标签值= 8 预测值= 6\n",
      "index=882标签值= 9 预测值= 7\n",
      "index=924标签值= 2 预测值= 7\n",
      "index=938标签值= 3 预测值= 5\n",
      "index=947标签值= 8 预测值= 7\n",
      "index=951标签值= 5 预测值= 4\n",
      "index=956标签值= 1 预测值= 2\n",
      "index=965标签值= 6 预测值= 0\n",
      "index=1014标签值= 6 预测值= 5\n",
      "index=1039标签值= 7 预测值= 2\n",
      "index=1050标签值= 2 预测值= 0\n",
      "index=1107标签值= 9 预测值= 3\n",
      "index=1112标签值= 4 预测值= 6\n",
      "index=1226标签值= 7 预测值= 2\n",
      "index=1232标签值= 9 预测值= 4\n",
      "index=1242标签值= 4 预测值= 9\n",
      "index=1247标签值= 9 预测值= 5\n",
      "index=1299标签值= 5 预测值= 7\n",
      "index=1319标签值= 8 预测值= 0\n",
      "index=1328标签值= 7 预测值= 9\n",
      "index=1331标签值= 5 预测值= 3\n",
      "index=1425标签值= 8 预测值= 4\n",
      "index=1466标签值= 5 预测值= 3\n",
      "index=1494标签值= 7 预测值= 0\n",
      "index=1530标签值= 8 预测值= 7\n",
      "index=1549标签值= 4 预测值= 6\n",
      "index=1553标签值= 9 预测值= 3\n",
      "index=1571标签值= 4 预测值= 9\n",
      "index=1601标签值= 3 预测值= 7\n",
      "index=1609标签值= 2 预测值= 6\n",
      "index=1621标签值= 0 预测值= 6\n",
      "index=1678标签值= 2 预测值= 0\n",
      "index=1717标签值= 8 预测值= 0\n",
      "index=1781标签值= 9 预测值= 6\n",
      "index=1878标签值= 8 预测值= 3\n",
      "index=1901标签值= 9 预测值= 4\n",
      "index=1941标签值= 7 预测值= 8\n",
      "index=1955标签值= 8 预测值= 2\n",
      "index=1982标签值= 6 预测值= 5\n",
      "index=2004标签值= 8 预测值= 9\n",
      "index=2016标签值= 7 预测值= 2\n",
      "index=2073标签值= 5 预测值= 6\n",
      "index=2098标签值= 2 预测值= 0\n",
      "index=2105标签值= 3 预测值= 5\n",
      "index=2109标签值= 3 预测值= 8\n",
      "index=2118标签值= 6 预测值= 0\n",
      "index=2130标签值= 4 预测值= 9\n",
      "index=2135标签值= 6 预测值= 1\n",
      "index=2224标签值= 5 预测值= 6\n",
      "index=2272标签值= 8 预测值= 6\n",
      "index=2293标签值= 9 预测值= 0\n",
      "index=2308标签值= 3 预测值= 5\n",
      "index=2358标签值= 1 预测值= 3\n",
      "index=2369标签值= 5 预测值= 8\n",
      "index=2387标签值= 9 预测值= 1\n",
      "index=2408标签值= 3 预测值= 5\n",
      "index=2454标签值= 6 预测值= 5\n",
      "index=2462标签值= 2 预测值= 0\n",
      "index=2488标签值= 2 预测值= 4\n",
      "index=2496标签值= 2 预测值= 3\n",
      "index=2515标签值= 5 预测值= 6\n",
      "index=2578标签值= 7 预测值= 2\n",
      "index=2597标签值= 5 预测值= 3\n",
      "index=2648标签值= 9 预测值= 0\n",
      "index=2654标签值= 6 预测值= 1\n",
      "index=2720标签值= 9 预测值= 4\n",
      "index=2769标签值= 9 预测值= 7\n",
      "index=2770标签值= 3 预测值= 7\n",
      "index=2771标签值= 4 预测值= 9\n",
      "index=2810标签值= 5 预测值= 3\n",
      "index=2863标签值= 9 预测值= 4\n",
      "index=2877标签值= 4 预测值= 9\n",
      "index=2896标签值= 8 预测值= 0\n",
      "index=2915标签值= 7 预测值= 3\n",
      "index=2921标签值= 3 预测值= 0\n",
      "index=2927标签值= 3 预测值= 2\n",
      "index=2938标签值= 4 预测值= 9\n",
      "index=2939标签值= 9 预测值= 7\n",
      "index=2941标签值= 9 预测值= 5\n",
      "index=2953标签值= 3 预测值= 5\n",
      "index=2995标签值= 6 预测值= 5\n",
      "index=3023标签值= 8 预测值= 5\n",
      "index=3030标签值= 6 预测值= 8\n",
      "index=3060标签值= 9 预测值= 7\n",
      "index=3108标签值= 3 预测值= 5\n",
      "index=3284标签值= 8 预测值= 7\n",
      "index=3369标签值= 9 预测值= 1\n",
      "index=3405标签值= 4 预测值= 9\n",
      "index=3475标签值= 3 预测值= 7\n",
      "index=3490标签值= 4 预测值= 9\n",
      "index=3503标签值= 9 预测值= 1\n",
      "index=3520标签值= 6 预测值= 4\n",
      "index=3558标签值= 5 预测值= 0\n",
      "index=3559标签值= 8 预测值= 6\n",
      "index=3597标签值= 9 预测值= 5\n",
      "index=3604标签值= 7 预测值= 0\n",
      "index=3702标签值= 5 预测值= 9\n",
      "index=3776标签值= 5 预测值= 8\n",
      "index=3780标签值= 4 预测值= 6\n",
      "index=3808标签值= 7 预测值= 8\n",
      "index=3831标签值= 9 预测值= 4\n",
      "index=3853标签值= 6 预测值= 5\n",
      "index=3893标签值= 5 预测值= 6\n",
      "index=3906标签值= 1 预测值= 3\n",
      "index=3941标签值= 4 预测值= 6\n",
      "index=3951标签值= 8 预测值= 7\n",
      "index=3976标签值= 7 预测值= 1\n",
      "index=3985标签值= 9 预测值= 4\n",
      "index=4007标签值= 7 预测值= 4\n",
      "index=4065标签值= 0 预测值= 5\n",
      "index=4075标签值= 8 预测值= 3\n",
      "index=4078标签值= 9 预测值= 8\n",
      "index=4116标签值= 8 预测值= 5\n",
      "index=4140标签值= 8 预测值= 2\n",
      "index=4156标签值= 2 预测值= 8\n",
      "index=4163标签值= 9 预测值= 0\n",
      "index=4176标签值= 2 预测值= 7\n",
      "index=4201标签值= 1 预测值= 7\n",
      "index=4212标签值= 1 预测值= 3\n",
      "index=4248标签值= 2 预测值= 8\n",
      "index=4259标签值= 9 预测值= 4\n",
      "index=4271标签值= 5 预测值= 3\n",
      "index=4289标签值= 2 预测值= 7\n",
      "index=4294标签值= 9 预测值= 7\n",
      "index=4373标签值= 4 预测值= 9\n",
      "index=4374标签值= 5 预测值= 6\n",
      "index=4382标签值= 4 预测值= 9\n",
      "index=4429标签值= 8 预测值= 5\n",
      "index=4433标签值= 7 预测值= 2\n",
      "index=4497标签值= 8 预测值= 7\n",
      "index=4498标签值= 7 预测值= 3\n",
      "index=4534标签值= 9 预测值= 3\n",
      "index=4536标签值= 6 预测值= 5\n",
      "index=4548标签值= 5 预测值= 6\n",
      "index=4601标签值= 8 预测值= 4\n",
      "index=4639标签值= 8 预测值= 9\n",
      "index=4721标签值= 4 预测值= 6\n",
      "index=4724标签值= 8 预测值= 0\n",
      "index=4743标签值= 8 预测值= 5\n",
      "index=4761标签值= 9 预测值= 4\n",
      "index=4807标签值= 8 预测值= 3\n",
      "index=4808标签值= 3 预测值= 5\n",
      "index=4823标签值= 9 预测值= 6\n",
      "index=4837标签值= 7 预测值= 2\n",
      "index=4860标签值= 4 预测值= 9\n",
      "index=4861标签值= 7 预测值= 3\n",
      "index=4880标签值= 0 预测值= 8\n",
      "index=4915标签值= 5 预测值= 8\n",
      "index=4944标签值= 2 预测值= 5\n",
      "index=4966标签值= 7 预测值= 9\n",
      "index=5078标签值= 3 预测值= 2\n",
      "index=5331标签值= 1 预测值= 6\n",
      "index=5401标签值= 6 预测值= 3\n",
      "index=5457标签值= 1 预测值= 8\n",
      "index=5642标签值= 1 预测值= 5\n",
      "index=5654标签值= 7 预测值= 2\n",
      "index=5687标签值= 3 预测值= 8\n",
      "index=5734标签值= 3 预测值= 7\n",
      "index=5763标签值= 2 预测值= 6\n",
      "index=5887标签值= 7 预测值= 0\n",
      "index=5888标签值= 4 预测值= 0\n",
      "index=5926标签值= 4 预测值= 9\n",
      "index=5935标签值= 3 预测值= 5\n",
      "index=5936标签值= 4 预测值= 9\n",
      "index=5955标签值= 3 预测值= 8\n",
      "index=5973标签值= 3 预测值= 8\n",
      "index=5982标签值= 5 预测值= 3\n",
      "index=6009标签值= 3 预测值= 5\n",
      "index=6011标签值= 3 预测值= 0\n",
      "index=6023标签值= 3 预测值= 5\n",
      "index=6030标签值= 3 预测值= 5\n",
      "index=6045标签值= 3 预测值= 5\n",
      "index=6059标签值= 3 预测值= 8\n",
      "index=6080标签值= 8 预测值= 0\n",
      "index=6101标签值= 1 预测值= 5\n",
      "index=6157标签值= 9 预测值= 0\n",
      "index=6172标签值= 9 预测值= 0\n",
      "index=6347标签值= 8 预测值= 2\n",
      "index=6555标签值= 8 预测值= 9\n",
      "index=6571标签值= 9 预测值= 7\n",
      "index=6572标签值= 1 预测值= 5\n",
      "index=6574标签值= 2 预测值= 6\n",
      "index=6597标签值= 0 预测值= 7\n",
      "index=6651标签值= 0 预测值= 8\n",
      "index=6755标签值= 8 预测值= 9\n",
      "index=6783标签值= 1 预测值= 6\n",
      "index=6967标签值= 9 预测值= 7\n",
      "index=7061标签值= 9 预测值= 7\n",
      "index=7081标签值= 9 预测值= 7\n",
      "index=7100标签值= 2 预测值= 1\n",
      "index=7256标签值= 9 预测值= 7\n",
      "index=7434标签值= 4 预测值= 8\n",
      "index=7451标签值= 5 预测值= 6\n",
      "index=7481标签值= 8 预测值= 5\n",
      "index=7736标签值= 9 预测值= 4\n",
      "index=7823标签值= 8 预测值= 0\n",
      "index=7849标签值= 3 预测值= 2\n",
      "index=7850标签值= 5 预测值= 0\n",
      "index=8091标签值= 2 预测值= 1\n",
      "index=8246标签值= 3 预测值= 9\n",
      "index=8325标签值= 0 预测值= 6\n",
      "index=8383标签值= 9 预测值= 5\n",
      "index=8408标签值= 8 预测值= 6\n",
      "index=8472标签值= 4 预测值= 9\n",
      "index=8502标签值= 5 预测值= 3\n",
      "index=8520标签值= 4 预测值= 9\n",
      "index=8522标签值= 8 预测值= 6\n",
      "index=8527标签值= 4 预测值= 9\n",
      "index=8863标签值= 5 预测值= 6\n",
      "index=9009标签值= 7 预测值= 2\n",
      "index=9015标签值= 7 预测值= 2\n",
      "index=9019标签值= 7 预测值= 2\n",
      "index=9024标签值= 7 预测值= 2\n",
      "index=9128标签值= 4 预测值= 7\n",
      "index=9252标签值= 9 预测值= 7\n",
      "index=9253标签值= 4 预测值= 9\n",
      "index=9385标签值= 8 预测值= 6\n",
      "index=9530标签值= 9 预测值= 7\n",
      "index=9544标签值= 9 预测值= 7\n",
      "index=9587标签值= 9 预测值= 4\n",
      "index=9664标签值= 2 预测值= 7\n",
      "index=9679标签值= 6 预测值= 5\n",
      "index=9692标签值= 9 预测值= 7\n",
      "index=9713标签值= 9 预测值= 7\n",
      "index=9729标签值= 5 预测值= 6\n",
      "index=9735标签值= 4 预测值= 9\n",
      "index=9740标签值= 9 预测值= 7\n",
      "index=9749标签值= 5 预测值= 6\n",
      "index=9768标签值= 2 预测值= 0\n",
      "index=9770标签值= 5 预测值= 0\n",
      "index=9779标签值= 2 预测值= 0\n",
      "index=9839标签值= 2 预测值= 7\n",
      "index=9858标签值= 6 预测值= 5\n",
      "index=9867标签值= 2 预测值= 8\n",
      "index=9904标签值= 2 预测值= 0\n",
      "index=9925标签值= 3 预测值= 8\n",
      "index=9944标签值= 3 预测值= 8\n",
      "总计：262\n"
     ]
    }
   ],
   "source": [
    "# 定义输出错误分类的函数\n",
    "def print_predict_errs(labels, prediction):\n",
    "    count=0\n",
    "    compare_lists = (prediction==np.argmax(labels, 1))\n",
    "    err_lists = [i for i in range(len(compare_lists)) if compare_lists[i] == False]\n",
    "    for x in err_lists:\n",
    "        print(\"index=\" + str(x) + \"标签值=\", np.argmax(labels[x]), \"预测值=\", prediction[x])\n",
    "        count = count+1\n",
    "    print(\"总计：\"+ str(count))\n",
    "\n",
    "print_predict_errs(labels=mnist.test.labels, prediction = prediction_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 多层神经网络建模与模型的保存还原\n",
    "H1_NN = 256   # 第一隐藏层神经元为256个\n",
    "H2_NN = 64    # 第二隐藏层神经元为64个\n",
    "# 输入层-第一隐藏层参数和偏置项\n",
    "W1 = tf.Variable(tf.truncated_normal([784, H1_NN], stddev = 0.1))\n",
    "b1 = tf.Variable(tf.zeros[H1_NN])\n",
    "# 第一隐藏层-第二隐藏层参数和偏置项\n",
    "W2 = tf.Variable(tf.truncated_normal([H1_NN, H2_NN], stddev = 0.1))\n",
    "b2 = tf.Variable(tf.zeros[H2_NN])\n",
    "# 第二隐藏层-输出层参数和偏置项\n",
    "W3 = tf.Variable(tf.truncated_normal([H2_NN, 10], stddev = 0.1))\n",
    "b2 = tf.Variable(tf.zeros[10])\n",
    "# 计算第一隐藏层结果\n",
    "Y1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "# 计算第二隐藏层结果\n",
    "Y2 = tf.nn.relu(tf.matmul(Y1, W2) + b2)\n",
    "# 计算输出结果\n",
    "forward = tf.matmul(Y2, W3) + b3\n",
    "pred = tf.nn.softmax(forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 01 Loss= 1.434194326 Accuracy= 0.9384\n",
      "Train Epoch: 02 Loss= 0.866662323 Accuracy= 0.9424\n",
      "Train Epoch: 03 Loss= 0.650168777 Accuracy= 0.9532\n",
      "Train Epoch: 04 Loss= 0.440463364 Accuracy= 0.9572\n",
      "Train Epoch: 05 Loss= 0.412544638 Accuracy= 0.9582\n",
      "Train Epoch: 06 Loss= 0.422783405 Accuracy= 0.9586\n",
      "Train Epoch: 07 Loss= 0.456409723 Accuracy= 0.9568\n",
      "Train Epoch: 08 Loss= 0.378219008 Accuracy= 0.9610\n",
      "Train Epoch: 09 Loss= 0.425614208 Accuracy= 0.9632\n",
      "Train Epoch: 10 Loss= 0.408308208 Accuracy= 0.9598\n",
      "Train Epoch: 11 Loss= 0.556892693 Accuracy= 0.9526\n",
      "Train Epoch: 12 Loss= 0.394996047 Accuracy= 0.9670\n",
      "Train Epoch: 13 Loss= 0.305846423 Accuracy= 0.9668\n",
      "Train Epoch: 14 Loss= 0.360596985 Accuracy= 0.9720\n",
      "Train Epoch: 15 Loss= 0.537532091 Accuracy= 0.9644\n",
      "Train Epoch: 16 Loss= 0.453889072 Accuracy= 0.9706\n",
      "Train Epoch: 17 Loss= 0.464279741 Accuracy= 0.9684\n",
      "Train Epoch: 18 Loss= 0.565885067 Accuracy= 0.9660\n",
      "Train Epoch: 19 Loss= 0.497817665 Accuracy= 0.9730\n",
      "Train Epoch: 20 Loss= 0.572404504 Accuracy= 0.9706\n",
      "Train Epoch: 21 Loss= 0.528316379 Accuracy= 0.9720\n",
      "Train Epoch: 22 Loss= 0.620926082 Accuracy= 0.9688\n",
      "Train Epoch: 23 Loss= 0.578144491 Accuracy= 0.9722\n",
      "Train Epoch: 24 Loss= 0.652855277 Accuracy= 0.9722\n",
      "Train Epoch: 25 Loss= 0.592573225 Accuracy= 0.9706\n",
      "Train Epoch: 26 Loss= 0.663275659 Accuracy= 0.9700\n",
      "Train Epoch: 27 Loss= 0.714536786 Accuracy= 0.9710\n",
      "Train Epoch: 28 Loss= 0.685616016 Accuracy= 0.9696\n",
      "Train Epoch: 29 Loss= 0.721705735 Accuracy= 0.9736\n",
      "Train Epoch: 30 Loss= 0.731054544 Accuracy= 0.9728\n",
      "Train Epoch: 31 Loss= 0.943427563 Accuracy= 0.9684\n",
      "Train Epoch: 32 Loss= 0.757692218 Accuracy= 0.9738\n",
      "Train Epoch: 33 Loss= 0.702651203 Accuracy= 0.9758\n",
      "Train Epoch: 34 Loss= 0.808527648 Accuracy= 0.9716\n",
      "Train Epoch: 35 Loss= 0.814881206 Accuracy= 0.9748\n",
      "Train Epoch: 36 Loss= 0.995520532 Accuracy= 0.9712\n",
      "Train Epoch: 37 Loss= 0.847636402 Accuracy= 0.9770\n",
      "Train Epoch: 38 Loss= 0.762745380 Accuracy= 0.9794\n",
      "Train Epoch: 39 Loss= 0.928503096 Accuracy= 0.9746\n",
      "Train Epoch: 40 Loss= 0.985768557 Accuracy= 0.9730\n",
      "Train Finished takes: 107.01\n"
     ]
    }
   ],
   "source": [
    "# 设置训练参数\n",
    "train_epochs = 40  # 训练轮数\n",
    "batch_size = 50   # 单次训练样本数（批次大小）\n",
    "total_batch = int(mnist.train.num_examples/batch_size)  # 一轮训练有多少批次\n",
    "display_step = 1  # 显示粒度\n",
    "learning_rate = 0.01  # 学习率\n",
    "# 结合Softmax的交叉熵损失函数，用于避免因为log(0)值为NaN造成的数据不稳定\n",
    "loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=forward, labels=y))\n",
    "# Adam优化器\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "from time import time\n",
    "startTime = time()\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    for batch in range(total_batch):\n",
    "        xs, ys = mnist.train.next_batch(batch_size)  # 读取批次数据\n",
    "        sess.run(optimizer, feed_dict={x:xs, y:ys})  # 执行批次训练\n",
    "    \n",
    "    # total_batch个批次训练完成后，使用验证数据计算误差与准确率；验证集没有分批\n",
    "    loss, acc = sess.run([loss_function, accuracy], feed_dict={x:mnist.validation.images, y:mnist.validation.labels})\n",
    "    # 打印训练过程中的详细信息\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Train Epoch:\", \"%02d\" % (epoch+1), \"Loss=\", \"{:.9f}\".format(loss), \"Accuracy=\", \"{:.4f}\".format(acc))\n",
    "\n",
    "# 显示运行总时间\n",
    "duration = time()-startTime\n",
    "print(\"Train Finished takes:\", \"{:.2f}\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "# 完成训练后，在测试集上评估模型的准确率(多层效果不一定优于单层，需要调试超参数)\n",
    "accu_test = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "print(\"Test Accuracy:\", accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义全连接层函数\n",
    "def fcn_layer(inputs, input_dim, output_dim, activation=None):\n",
    "    W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros([output_dim]))\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构建三隐层模型\n",
    "H1_NN = 256\n",
    "H2_NN = 64\n",
    "H3_NN = 32\n",
    "# 构建输入层\n",
    "x = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "# 构建隐藏层1\n",
    "h1 = fcn_layer(inputs=x, input_dim=784, output_dim=H1_NN, activation=tf.nn.relu)\n",
    "# 构建隐藏层2\n",
    "h2 = fcn_layer(inputs=h1, input_dim=H1_NN, output_dim=H2_NN, activation=tf.nn.relu)\n",
    "# 构建隐藏层3\n",
    "h3 = fcn_layer(inputs=h2, input_dim=H2_NN, output_dim=H3_NN, activation=tf.nn.relu)\n",
    "# 构建输出层\n",
    "forward = fcn_layer(inputs=h3, input_dim=H3_NN, output_dim=10, activation=None)\n",
    "pred = tf.nn.softmax(forward)\n",
    "# 训练过程同上省略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 存储模型的粒度\n",
    "save_step = 5\n",
    "# 创建保存模型文件的目录\n",
    "import os\n",
    "ckpt_dir = \"./ckpt_dir/\"\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "# 声明完所有变量后，调用tf.train.Saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-4c955e09b0e6>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Train Epoch: 01 Loss= 0.179056197 Accuracy= 0.9506\n",
      "Train Epoch: 02 Loss= 0.135319218 Accuracy= 0.9638\n",
      "Train Epoch: 03 Loss= 0.142146289 Accuracy= 0.9674\n",
      "Train Epoch: 04 Loss= 0.185633332 Accuracy= 0.9626\n",
      "Train Epoch: 05 Loss= 0.131845400 Accuracy= 0.9696\n",
      "mnist_h256_model_000005.ckpt saved\n",
      "Train Epoch: 06 Loss= 0.121152267 Accuracy= 0.9740\n",
      "Train Epoch: 07 Loss= 0.178398639 Accuracy= 0.9696\n",
      "Train Epoch: 08 Loss= 0.126798630 Accuracy= 0.9738\n",
      "Train Epoch: 09 Loss= 0.110531285 Accuracy= 0.9730\n",
      "Train Epoch: 10 Loss= 0.136402741 Accuracy= 0.9702\n",
      "mnist_h256_model_000010.ckpt saved\n",
      "Train Epoch: 11 Loss= 0.136622071 Accuracy= 0.9688\n",
      "Train Epoch: 12 Loss= 0.161598042 Accuracy= 0.9692\n",
      "Train Epoch: 13 Loss= 0.124132968 Accuracy= 0.9766\n",
      "Train Epoch: 14 Loss= 0.129855081 Accuracy= 0.9730\n",
      "Train Epoch: 15 Loss= 0.235727340 Accuracy= 0.9574\n",
      "mnist_h256_model_000015.ckpt saved\n",
      "Train Epoch: 16 Loss= 0.271114051 Accuracy= 0.9650\n",
      "Train Epoch: 17 Loss= 0.128859103 Accuracy= 0.9762\n",
      "Train Epoch: 18 Loss= 0.127217382 Accuracy= 0.9774\n",
      "Train Epoch: 19 Loss= 0.172373503 Accuracy= 0.9738\n",
      "Train Epoch: 20 Loss= 0.144384846 Accuracy= 0.9792\n",
      "mnist_h256_model_000020.ckpt saved\n",
      "Train Epoch: 21 Loss= 0.172625348 Accuracy= 0.9758\n",
      "Train Epoch: 22 Loss= 0.149324566 Accuracy= 0.9754\n",
      "Train Epoch: 23 Loss= 0.183878571 Accuracy= 0.9752\n",
      "Train Epoch: 24 Loss= 0.152910262 Accuracy= 0.9782\n",
      "Train Epoch: 25 Loss= 0.172354132 Accuracy= 0.9708\n",
      "mnist_h256_model_000025.ckpt saved\n",
      "Train Epoch: 26 Loss= 0.177063003 Accuracy= 0.9690\n",
      "Train Epoch: 27 Loss= 0.181809500 Accuracy= 0.9712\n",
      "Train Epoch: 28 Loss= 0.247305080 Accuracy= 0.9692\n",
      "Train Epoch: 29 Loss= 0.189345971 Accuracy= 0.9726\n",
      "Train Epoch: 30 Loss= 0.203567401 Accuracy= 0.9704\n",
      "mnist_h256_model_000030.ckpt saved\n",
      "Train Epoch: 31 Loss= 0.183643296 Accuracy= 0.9742\n",
      "Train Epoch: 32 Loss= 0.243939325 Accuracy= 0.9720\n",
      "Train Epoch: 33 Loss= 0.215405807 Accuracy= 0.9738\n",
      "Train Epoch: 34 Loss= 0.188512251 Accuracy= 0.9756\n",
      "Train Epoch: 35 Loss= 0.211891651 Accuracy= 0.9756\n",
      "mnist_h256_model_000035.ckpt saved\n",
      "Train Epoch: 36 Loss= 0.243984833 Accuracy= 0.9772\n",
      "Train Epoch: 37 Loss= 0.258173674 Accuracy= 0.9776\n",
      "Train Epoch: 38 Loss= 0.285135925 Accuracy= 0.9724\n",
      "Train Epoch: 39 Loss= 0.207994923 Accuracy= 0.9734\n",
      "Train Epoch: 40 Loss= 0.286713332 Accuracy= 0.9732\n",
      "mnist_h256_model_000040.ckpt saved\n",
      "Model saved!\n",
      "Train Finished takes: 135.81\n"
     ]
    }
   ],
   "source": [
    "# 设置训练参数\n",
    "train_epochs = 40  # 训练轮数\n",
    "batch_size = 50   # 单次训练样本数（批次大小）\n",
    "total_batch = int(mnist.train.num_examples/batch_size)  # 一轮训练有多少批次\n",
    "display_step = 1  # 显示粒度\n",
    "learning_rate = 0.01  # 学习率\n",
    "# 结合Softmax的交叉熵损失函数，用于避免因为log(0)值为NaN造成的数据不稳定\n",
    "loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=forward, labels=y))\n",
    "# Adam优化器\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "from time import time\n",
    "startTime = time()\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    for batch in range(total_batch):\n",
    "        xs, ys = mnist.train.next_batch(batch_size)  # 读取批次数据\n",
    "        sess.run(optimizer, feed_dict={x:xs, y:ys})  # 执行批次训练\n",
    "    \n",
    "    # total_batch个批次训练完成后，使用验证数据计算误差与准确率；验证集没有分批\n",
    "    loss, acc = sess.run([loss_function, accuracy], feed_dict={x:mnist.validation.images, y:mnist.validation.labels})\n",
    "    # 打印训练过程中的详细信息\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Train Epoch:\", \"%02d\" % (epoch+1), \"Loss=\", \"{:.9f}\".format(loss), \"Accuracy=\", \"{:.4f}\".format(acc))\n",
    "    if(epoch+1) % save_step == 0:\n",
    "        saver.save(sess, os.path.join(ckpt_dir, 'mnist_h256_model_{:06d}.ckpt'.format(epoch+1)))  # 存储模型\n",
    "        print('mnist_h256_model_{:06d}.ckpt saved'.format(epoch+1))\n",
    "\n",
    "saver.save(sess, os.path.join(ckpt_dir, 'mnist_h256_model.ckpt'))\n",
    "print(\"Model saved!\")\n",
    "# 显示运行总时间\n",
    "duration = time()-startTime\n",
    "print(\"Train Finished takes:\", \"{:.2f}\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore model from./ckpt_dir/mnist_h256_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 模型的还原\n",
    "# 定义相同结构的模型：构建输入层、隐藏层、输出层\n",
    "x = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "h1 = fcn_layer(inputs=x, input_dim=784, output_dim=256, activation=tf.nn.relu)\n",
    "h2 = fcn_layer(inputs=h1, input_dim=256, output_dim=64, activation=tf.nn.relu)\n",
    "h3 = fcn_layer(inputs=h2, input_dim=64, output_dim=32, activation=tf.nn.relu)\n",
    "forward = fcn_layer(inputs=h3, input_dim=32, output_dim=10, activation=None)\n",
    "pred = tf.nn.softmax(forward)\n",
    "# 必须指定为模型文件的存放目录\n",
    "ckpt_dir = \"./ckpt_dir/\"\n",
    "# 读取模型 创建saver\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)  # 从已保存的模型中读取参数\n",
    "    print(\"Restore model from\" + ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorBoard应用进阶参考pdf\n",
    "# TensorFlow游乐场演示：http://playground.tensorflow.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
