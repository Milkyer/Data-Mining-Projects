{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex      region   income married  children  car save_act  \\\n",
      "0   48  FEMALE  INNER_CITY  17546.0      NO         1   NO       NO   \n",
      "1   40    MALE        TOWN  30085.1     YES         3  YES       NO   \n",
      "2   51  FEMALE  INNER_CITY  16575.4     YES         0  YES      YES   \n",
      "3   23  FEMALE        TOWN  20375.4     YES         3   NO       NO   \n",
      "4   57  FEMALE       RURAL  50576.3     YES         0   NO      YES   \n",
      "\n",
      "  current_act mortgage  pep  \n",
      "0          NO       NO  YES  \n",
      "1         YES      YES   NO  \n",
      "2         YES       NO   NO  \n",
      "3         YES       NO   NO  \n",
      "4          NO       NO   NO  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "bank=pd.read_csv(\"G:\\\\XX\\\\Data\\\\bank.csv\", index_col=False)\n",
    "print(bank.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "Name: car, dtype: int8\n"
     ]
    }
   ],
   "source": [
    "# 将分类变量转化为数值变量\n",
    "for name in [\"sex\", \"region\", \"married\", \"car\", \"save_act\", \"current_act\", \"mortgage\", \"pep\"]:\n",
    "    col=pd.Categorical(bank[name])\n",
    "    bank[name]=col.codes\n",
    "print(bank[\"car\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy(column):\n",
    "    # Compute the counts of each unique value in the column\n",
    "    counts = numpy.bincount(column)\n",
    "    # Divide by the total column length to get a probability\n",
    "    probabilities = counts / len(column)\n",
    "    # Initialize the entropy to 0\n",
    "    entropy = 0\n",
    "    # Loop through the probabilities, and add each one to the total entropy\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    return -entropy\n",
    "def calc_information_gain(data, split_name, target_name):\n",
    "    # Calculate the original entropy\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    # Find the median of the column we're splitting\n",
    "    column = data[split_name]\n",
    "    median = column.median()\n",
    "    # Make two subsets of the data, based on the median\n",
    "    left_split = data[column <= median]\n",
    "    right_split = data[column > median]\n",
    "    # Loop through the splits and calculate the subset entropies\n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    # Return information gain\n",
    "    return original_entropy - to_subtract\n",
    "columns = [\"age\", \"sex\", \"region\", \"income\", \"married\", \"children\", \"car\", \"save_act\", \"current_act\", \"mortgage\"]\n",
    "def find_best_column(data, target_name, columns):\n",
    "    information_gains = []\n",
    "    # Loop through and compute information gains\n",
    "    for col in columns:\n",
    "        information_gain = calc_information_gain(data, col, \"pep\")\n",
    "        information_gains.append(information_gain)\n",
    "    # Find the name of the column with the highest gain\n",
    "    highest_gain_index = information_gains.index(max(information_gains))\n",
    "    highest_gain = columns[highest_gain_index]\n",
    "    return highest_gain\n",
    "\n",
    "bank_split = find_best_column(bank, \"pep\", columns)\n",
    "print(bank_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将数据集划分为训练集：测试集=8:2\n",
    "np.random.seed(1)\n",
    "bank=bank.reindex(np.random.permutation(bank.index))\n",
    "train_max_row=math.floor(bank.shape[0]* 0.8)\n",
    "train = bank[0: train_max_row]\n",
    "test = bank[train_max_row:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  region   income  married  children  car  save_act  current_act  \\\n",
      "446   52    0       3  43719.5        1         0    0         1            1   \n",
      "404   24    0       0  13864.6        1         3    0         1            1   \n",
      "509   23    0       1  11215.3        1         2    1         1            1   \n",
      "455   27    0       0  11866.4        1         0    1         1            1   \n",
      "201   46    0       3  41627.1        1         0    0         1            1   \n",
      "\n",
      "     mortgage  pep  \n",
      "446         0    0  \n",
      "404         0    1  \n",
      "509         0    1  \n",
      "455         0    0  \n",
      "201         1    0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from matplotlib import gridspec\n",
    "# import seaborn as sns\n",
    "columns = [\"age\", \"sex\", \"region\", \"income\", \"married\", \"children\", \"car\", \"save_act\", \"current_act\", \"mortgage\"]\n",
    "# col=['age', 'income']\n",
    "# Normalizer().fit_transform(bank[col])\n",
    "print(bank.head(5))\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import chi2\n",
    "# selector = SelectKBest(chi2, k=5)\n",
    "# optimized_columns = selector.fit_transform(bank[columns], bank['pep'])\n",
    "# print(selector)\n",
    "# SelectKBest(chi2, k=5).fit_transform(bank[columns], bank['pep'])\n",
    "\n",
    "# plt.figure(figsize=(8,10*4))\n",
    "# v_features = bank[columns].columns\n",
    "# gs = gridspec.GridSpec(10, 1)\n",
    "# for i, cn in enumerate(bank[v_features]):\n",
    "#     ax = plt.subplot(gs[i])\n",
    "#     sns.distplot(bank[bank['pep'] == 1][cn])\n",
    "#     sns.distplot(bank[bank['pep'] == 0][cn])\n",
    "#     ax.set_xlabel('')\n",
    "#     ax.set_title('histogram of feature:' + str(cn))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 13, 'splitter': 'best'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 决策树模型调参寻优\n",
    "hyperparameters={\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "    \"max_depth\": range(1,20,2),\n",
    "    \"min_samples_split\": range(3,16)\n",
    "}\n",
    "clf = DecisionTreeClassifier()\n",
    "grid=GridSearchCV(clf, param_grid=hyperparameters, cv=10)\n",
    "grid.fit(train[columns], train[\"pep\"])\n",
    "best_params=grid.best_params_\n",
    "best_score=grid.best_score_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64  5]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        69\n",
      "           1       0.90      0.88      0.89        51\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       120\n",
      "   macro avg       0.91      0.90      0.91       120\n",
      "weighted avg       0.91      0.91      0.91       120\n",
      "\n",
      "决策树模型的测试集正确率为 0.9083333333333333\n",
      "决策树模型的测试集AUC值为 0.9049445865302643\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=7, min_samples_split=14)\n",
    "clf.fit(train[columns], train[\"pep\"])\n",
    "prediction=clf.predict(test[columns])\n",
    "\n",
    "# 混淆矩阵的测试集评测指标\n",
    "# f1=metrics.f1_score(test['pep'], prediction)\n",
    "# print(\"决策树模型的测试集F1值为\",f1)\n",
    "# cm=metrics.confusion_matrix(test['pep'], prediction)\n",
    "# tn, fp, fn, tp = cm.ravel()\n",
    "# accuracy=(tp + tn) / (tp + fn + fp + tn)\n",
    "# print(\"决策树模型的测试集正确率为\",accuracy)\n",
    "# presision= tp / (tp + fp)\n",
    "# print(\"决策树模型的测试集准确率为\",presision)\n",
    "# recall= tp / (tp + fn)\n",
    "# print(\"决策树模型的测试集召回率为\",recall)\n",
    "\n",
    "# 决策树模型的测试集评测结果\n",
    "print(metrics.confusion_matrix(test['pep'], prediction))\n",
    "print(metrics.classification_report(test['pep'], prediction))\n",
    "accuracy = metrics.accuracy_score(test[\"pep\"], prediction)\n",
    "print(\"决策树模型的测试集正确率为\",accuracy)\n",
    "auc = roc_auc_score(test[\"pep\"], prediction)\n",
    "print(\"决策树模型的测试集AUC值为\", auc)\n",
    "\n",
    "# DT分类算法的五折交叉验证的评测指标\n",
    "accuracy = cross_val_score(clf, train[columns], train[\"pep\"], scoring='accuracy', cv=5)\n",
    "precision = cross_val_score(clf, train[columns], train[\"pep\"], scoring='precision', cv=5)\n",
    "recall = cross_val_score(clf, train[columns], train[\"pep\"], scoring='recall', cv=5)\n",
    "f1_score = cross_val_score(clf, train[columns], train[\"pep\"], scoring='f1', cv=5)\n",
    "auc = cross_val_score(clf, train[columns], train[\"pep\"], scoring='roc_auc', cv=5)\n",
    "print(\"准确率:\",accuracy.mean())\n",
    "print(\"精确率:\",precision.mean())\n",
    "print(\"召回率:\",recall.mean())\n",
    "print(\"F1_score:\",f1_score.mean())\n",
    "print(\"AUC:\",auc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "with open(\"G:\\\\XX\\\\Data\\\\bank.dot\", 'w') as f:\n",
    "    f=tree.export_graphviz(clf, feature_names=columns, class_names=['NO', 'YES'], filled=True, rounded=True, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KNN分类模型\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "# 绘制折线图：基于F1值找出最优K值为27\n",
    "def plot_dict(dictionary):\n",
    "    pd.Series(dictionary).plot(figsize=(8,4), xlim=(1,50), ylim=(0.4,0.6), marker='o', markersize=3)\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"F1 score\")\n",
    "    plt.xticks(range(1,50,2))\n",
    "    plt.show()\n",
    "    \n",
    "knn_f1 = dict()\n",
    "for k in range(1,50,2):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train[columns], train['pep'])\n",
    "    prediction = knn.predict(test[columns])\n",
    "    f1=metrics.f1_score(test['pep'], prediction)\n",
    "    knn_f1[k]=f1\n",
    "plot_dict(knn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# hyperparameters = {\n",
    "#     \"n_neighbors\": range(1,30,2),\n",
    "#     \"weights\": [\"distance\", \"uniform\"],\n",
    "#     \"algorithm\": ['brute'],\n",
    "#     \"p\": [1,2]\n",
    "# }\n",
    "# knn=KNeighborsClassifier()\n",
    "# grid=GridSearchCV(knn, param_grid=hyperparameters, cv=10)\n",
    "# grid.fit(train[columns], train['pep'])\n",
    "# best_params=grid.best_params_\n",
    "# print(best_params)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=27)\n",
    "knn.fit(train[columns], train['pep'])\n",
    "prediction = knn.predict(test[columns])\n",
    "\n",
    "print(metrics.confusion_matrix(test['pep'], prediction))\n",
    "print(metrics.classification_report(test['pep'], prediction))\n",
    "accuracy = metrics.accuracy_score(test[\"pep\"], prediction)\n",
    "print(\"KNN模型的测试集正确率为\",accuracy)\n",
    "auc = roc_auc_score(test[\"pep\"], prediction)\n",
    "print(\"KNN模型的测试集AUC值为\", auc)\n",
    "\n",
    "# # KNN分类算法的五折交叉验证的评测指标\n",
    "accuracy = cross_val_score(knn, train[columns], train[\"pep\"], scoring='accuracy', cv=5)\n",
    "precision = cross_val_score(knn, train[columns], train[\"pep\"], scoring='precision', cv=5)\n",
    "recall = cross_val_score(knn, train[columns], train[\"pep\"], scoring='recall', cv=5)\n",
    "f1_score = cross_val_score(knn, train[columns], train[\"pep\"], scoring='f1', cv=5)\n",
    "auc = cross_val_score(knn, train[columns], train[\"pep\"], scoring='roc_auc', cv=5)\n",
    "print(\"准确率:\",accuracy.mean())\n",
    "print(\"精确率:\",precision.mean())\n",
    "print(\"召回率:\",recall.mean())\n",
    "print(\"F1_score:\",f1_score.mean())\n",
    "print(\"AUC:\",auc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2.0, 'gamma': 0.125, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "# train['pep1']=train['pep']\n",
    "# test['pep1']=test['pep']\n",
    "# train.loc[train.pep==0, 'pep1']=-1\n",
    "# test.loc[test.pep==0, 'pep1']=-1\n",
    "\n",
    "svc = SVC()\n",
    "c_range = np.logspace(-5, 15, 11, base=2)\n",
    "gamma_range = np.logspace(-9, 3, 13, base=2)\n",
    "# 网格搜索交叉验证的参数范围，10折交叉\n",
    "param_grid = [{'kernel': ['rbf'], 'C': c_range, 'gamma': gamma_range}]\n",
    "grid = GridSearchCV(svc, param_grid, cv=10, n_jobs=-1)\n",
    "clf = grid.fit(train[columns], train[\"pep\"])\n",
    "best_params=grid.best_params_\n",
    "best_score=grid.best_score_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69  0]\n",
      " [51  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73        69\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       120\n",
      "   macro avg       0.29      0.50      0.37       120\n",
      "weighted avg       0.33      0.57      0.42       120\n",
      "\n",
      "SVM模型的测试集正确率为 0.575\n",
      "SVM模型的测试集AUC值为 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "svc = SVC(kernel='rbf', C=2.0, gamma= 0.125, class_weight='balanced')\n",
    "svc.fit(train[columns], train['pep'])\n",
    "prediction = svc.predict(test[columns])\n",
    "\n",
    "print(metrics.confusion_matrix(test['pep'], prediction))\n",
    "print(metrics.classification_report(test['pep'], prediction))\n",
    "accuracy = metrics.accuracy_score(test[\"pep\"], prediction)\n",
    "print(\"SVM模型的测试集正确率为\",accuracy)\n",
    "auc = roc_auc_score(test[\"pep1\"], prediction)\n",
    "print(\"SVM模型的测试集AUC值为\", auc)\n",
    "\n",
    "# SVM分类算法的五折交叉验证的评测指标\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "accuracy = cross_val_score(svc, train[columns], train[\"pep\"], scoring='accuracy', cv=5)\n",
    "precision = cross_val_score(svc, train[columns], train[\"pep\"], scoring='precision', cv=5)\n",
    "recall = cross_val_score(svc, train[columns], train[\"pep\"], scoring='recall', cv=5)\n",
    "f1_score = cross_val_score(svc, train[columns], train[\"pep\"], scoring='f1', cv=5)\n",
    "auc = cross_val_score(svc, train[columns], train[\"pep\"], scoring='roc_auc', cv=5)\n",
    "print(\"准确率:\",accuracy.mean())\n",
    "print(\"精确率:\",precision.mean())\n",
    "print(\"召回率:\",recall.mean())\n",
    "print(\"F1_score:\",f1_score.mean())\n",
    "print(\"AUC:\",auc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train[columns], train['pep'])\n",
    "prediction = gnb.predict(test[columns])\n",
    "\n",
    "print(metrics.confusion_matrix(test['pep'], prediction))\n",
    "print(metrics.classification_report(test['pep'], prediction))\n",
    "accuracy = metrics.accuracy_score(test[\"pep\"], prediction)\n",
    "print(\"NB模型的测试集正确率为\",accuracy)\n",
    "auc = roc_auc_score(test[\"pep\"], prediction)\n",
    "print(\"NB模型的测试集AUC值为\", auc)\n",
    "\n",
    "# NB分类算法的五折交叉验证的评测指标\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# accuracy = cross_val_score(gnb, train[columns], train[\"pep\"], scoring='accuracy', cv=5)\n",
    "# precision = cross_val_score(gnb, train[columns], train[\"pep\"], scoring='precision', cv=5)\n",
    "# recall = cross_val_score(gnb, train[columns], train[\"pep\"], scoring='recall', cv=5)\n",
    "# f1_score = cross_val_score(gnb, train[columns], train[\"pep\"], scoring='f1', cv=5)\n",
    "# auc = cross_val_score(gnb, train[columns], train[\"pep\"], scoring='roc_auc', cv=5)\n",
    "# print(\"准确率:\",accuracy.mean())\n",
    "# print(\"精确率:\",precision.mean())\n",
    "# print(\"召回率:\",recall.mean())\n",
    "# print(\"F1_score:\",f1_score.mean())\n",
    "# print(\"AUC:\",auc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(train[columns], train['pep'])\n",
    "prediction = mnb.predict(test[columns])\n",
    "\n",
    "# NB分类算法的五折交叉验证的评测指标\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "accuracy = cross_val_score(mnb, train[columns], train[\"pep\"], scoring='accuracy', cv=5)\n",
    "precision = cross_val_score(mnb, train[columns], train[\"pep\"], scoring='precision', cv=5)\n",
    "recall = cross_val_score(mnb, train[columns], train[\"pep\"], scoring='recall', cv=5)\n",
    "f1_score = cross_val_score(mnb, train[columns], train[\"pep\"], scoring='f1', cv=5)\n",
    "auc = cross_val_score(mnb, train[columns], train[\"pep\"], scoring='roc_auc', cv=5)\n",
    "print(\"准确率:\",accuracy.mean())\n",
    "print(\"精确率:\",precision.mean())\n",
    "print(\"召回率:\",recall.mean())\n",
    "print(\"F1_score:\",f1_score.mean())\n",
    "print(\"AUC:\",auc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(train[columns], train['pep'])\n",
    "prediction = bnb.predict(test[columns])\n",
    "\n",
    "# NB分类算法的五折交叉验证的评测指标\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "accuracy = cross_val_score(bnb, train[columns], train[\"pep\"], scoring='accuracy', cv=5)\n",
    "precision = cross_val_score(bnb, train[columns], train[\"pep\"], scoring='precision', cv=5)\n",
    "recall = cross_val_score(bnb, train[columns], train[\"pep\"], scoring='recall', cv=5)\n",
    "f1_score = cross_val_score(bnb, train[columns], train[\"pep\"], scoring='f1', cv=5)\n",
    "auc = cross_val_score(bnb, train[columns], train[\"pep\"], scoring='roc_auc', cv=5)\n",
    "print(\"准确率:\",accuracy.mean())\n",
    "print(\"精确率:\",precision.mean())\n",
    "print(\"召回率:\",recall.mean())\n",
    "print(\"F1_score:\",f1_score.mean())\n",
    "print(\"AUC:\",auc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
